# Tatoeba translation results

Note that some links to the actual models below are broken
because the models are not yet released or their performance is too poor
to be useful for anything.

| Model | Test Set | chrF2 | BLEU |
|:--|---|--:|--:|
| | lang = ara-epo | | | | |
| [afa-art/opus4m+btTCv20210807](../models/afa-art) | tatoeba-v2021-08-07 | 0.586 | 36.9 |
| | lang = bre-eng | | | | |
| [cel-eng/opus4m+btTCv20210807](../models/cel-eng) | tatoeba-v2021-08-07 | 0.469 | 30.2 |
| | lang = cym-eng | | | | |
| [cel-eng/opus4m+btTCv20210807](../models/cel-eng) | tatoeba-v2021-08-07 | 0.677 | 51.1 |
| | lang = eng-kaz | | | | |
| [eng-kaz/opusTCv20210807+bt](../models/eng-kaz) | tatoeba-v2021-08-07 | 0.492 | 20.7 |
| | lang = gle-eng | | | | |
| [cel-eng/opus4m+btTCv20210807](../models/cel-eng) | tatoeba-v2021-08-07 | 0.635 | 46.7 |
| | lang = heb-epo | | | | |
| [afa-art/opus4m+btTCv20210807](../models/afa-art) | tatoeba-v2021-08-07 | 0.546 | 34.6 |
| | lang = ltz-eng | | | | |
| [gmw-eng/opus4m+btTCv20210807](../models/gmw-eng) | tatoeba-v2021-08-07 | 0.289 | 14.6 |
