# opus-2020-06-17.zip

* dataset: opus
* model: transformer-align
* source language(s): ind zsm_Latn
* target language(s): deu
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-06-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/msa-deu/opus-2020-06-17.zip)
* test set translations: [opus-2020-06-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/msa-deu/opus-2020-06-17.test.txt)
* test set scores: [opus-2020-06-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/msa-deu/opus-2020-06-17.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.msa.deu 	| 36.5 	| 0.584 |





# opus-2021-02-24.zip

* dataset: opus
* model: transformer
* source language(s): ind jak min msa zlm zsm
* target language(s): deu
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-24.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/msa-deu/opus-2021-02-24.zip)
* test set translations: [opus-2021-02-24.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/msa-deu/opus-2021-02-24.test.txt)
* test set scores: [opus-2021-02-24.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/msa-deu/opus-2021-02-24.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.ind-deu 	| 37.8 	| 0.592 	| 488 	| 3817 	| 0.968 |
| Tatoeba-test.msa-deu 	| 37.9 	| 0.592 	| 535 	| 4198 	| 0.969 |
| Tatoeba-test.zsm_Latn-deu 	| 37.1 	| 0.569 	| 47 	| 379 	| 0.981 |

