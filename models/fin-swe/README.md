# opus-2021-02-16.zip

* dataset: opus
* model: transformer-align
* source language(s): fin
* target language(s): swe
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-16.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-2021-02-16.zip)
* test set translations: [opus-2021-02-16.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-2021-02-16.test.txt)
* test set scores: [opus-2021-02-16.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-2021-02-16.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| fiskmo_testset-finswe.fin.swe 	| 27.9 	| 0.602 |
| Tatoeba-test.fin.swe 	| 54.2 	| 0.700 |
| Tatoeba-test.fin-swe.fin.swe 	| 54.2 	| 0.700 |


# opus-tuned4OpenSubtitles-2021-02-18.zip

* dataset: opus-tuned4OpenSubtitles
* model: transformer
* source language(s): fin
* target language(s): swe
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-tuned4OpenSubtitles-2021-02-18.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-tuned4OpenSubtitles-2021-02-18.zip)
* test set translations: [opus-tuned4OpenSubtitles-2021-02-18.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-tuned4OpenSubtitles-2021-02-18.test.txt)
* test set scores: [opus-tuned4OpenSubtitles-2021-02-18.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-tuned4OpenSubtitles-2021-02-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.fin-swe 	| 53.4 	| 0.690 	| 2500 	| 16762 	| 0.974 |


# opus-2021-02-19.zip

* dataset: opus
* model: transformer-align
* source language(s): fin
* target language(s): swe
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-19.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-2021-02-19.zip)
* test set translations: [opus-2021-02-19.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-2021-02-19.test.txt)
* test set scores: [opus-2021-02-19.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opus-2021-02-19.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.fin-swe 	| 28.2 	| 0.604 	| 523 	| 9479 	| 1.000 |
| MeMAD-YLE-test.FIH-SWE.fin-swe 	| 17.0 	| 0.435 	| 625 	| 6825 	| 1.000 |
| MeMAD-YLE-test.FIN-SWE.fin-swe 	| 22.3 	| 0.468 	| 1253 	| 13359 	| 0.914 |
| MeMAD-YLE-test.FIN-SWH.fin-swe 	| 18.2 	| 0.433 	| 2837 	| 28454 	| 0.926 |
| Tatoeba-test.fin-swe 	| 54.5 	| 0.701 	| 2500 	| 16762 	| 0.980 |


# opusTCv20210807+bt-2021-08-26.zip

* dataset: opusTCv20210807+bt
* model: transformer-align
* source language(s): fin
* target language(s): swe
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-08-26.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opusTCv20210807+bt-2021-08-26.zip)
* test set translations: [opusTCv20210807+bt-2021-08-26.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opusTCv20210807+bt-2021-08-26.test.txt)
* test set scores: [opusTCv20210807+bt-2021-08-26.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fin-swe/opusTCv20210807+bt-2021-08-26.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.fin-swe 	| 31.8 	| 0.639 	| 523 	| 9479 	| 1.000 |
| Tatoeba-test-v2021-08-07.fin-swe 	| 55.0 	| 0.709 	| 2841 	| 19111 	| 0.976 |

