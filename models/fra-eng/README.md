# opus-2021-02-16.zip

* dataset: opus
* model: transformer-align
* source language(s): fra
* target language(s): eng
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-16.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-16.zip)
* test set translations: [opus-2021-02-16.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-16.test.txt)
* test set scores: [opus-2021-02-16.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-16.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdiscussdev2015-enfr-fraeng.fra.eng 	| 33.9 	| 0.585 |
| newsdiscusstest2015-enfr-fraeng.fra.eng 	| 38.9 	| 0.617 |
| newssyscomb2009-fraeng.fra.eng 	| 30.2 	| 0.571 |
| news-test2008-fraeng.fra.eng 	| 26.2 	| 0.542 |
| newstest2009-fraeng.fra.eng 	| 30.1 	| 0.570 |
| newstest2010-fraeng.fra.eng 	| 32.1 	| 0.590 |
| newstest2011-fraeng.fra.eng 	| 32.9 	| 0.597 |
| newstest2012-fraeng.fra.eng 	| 32.9 	| 0.592 |
| newstest2013-fraeng.fra.eng 	| 34.0 	| 0.592 |
| newstest2014-fren-fraeng.fra.eng 	| 37.8 	| 0.632 |
| Tatoeba-test.fra.eng 	| 57.7 	| 0.722 |
| Tatoeba-test.fra-eng.fra.eng 	| 57.7 	| 0.722 |

# opus-2021-02-17.zip

* dataset: opus
* model: transformer-align
* source language(s): fra
* target language(s): eng
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-17.zip)
* test set translations: [opus-2021-02-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-17.test.txt)
* test set scores: [opus-2021-02-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-17.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.fra-eng 	| 57.9 	| 0.723 	| 10000 	| 77174 	| 0.982 |

# opus-2021-02-19.zip

* dataset: opus
* model: transformer-align
* source language(s): fra
* target language(s): eng
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-19.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-19.zip)
* test set translations: [opus-2021-02-19.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-19.test.txt)
* test set scores: [opus-2021-02-19.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-19.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newsdiscussdev2015-enfr.fra-eng 	| 33.9 	| 0.585 	| 1500 	| 27759 	| 0.958 |
| newsdiscusstest2015-enfr.fra-eng 	| 39.3 	| 0.620 	| 1500 	| 26995 	| 0.992 |
| newssyscomb2009.fra-eng 	| 30.7 	| 0.573 	| 502 	| 11821 	| 0.996 |
| news-test2008.fra-eng 	| 26.3 	| 0.543 	| 2051 	| 49380 	| 1.000 |
| newstest2009.fra-eng 	| 30.5 	| 0.572 	| 2525 	| 65402 	| 1.000 |
| newstest2010.fra-eng 	| 32.3 	| 0.591 	| 2489 	| 61724 	| 1.000 |
| newstest2011.fra-eng 	| 33.2 	| 0.599 	| 3003 	| 74681 	| 1.000 |
| newstest2012.fra-eng 	| 33.0 	| 0.592 	| 3003 	| 72812 	| 1.000 |
| newstest2013.fra-eng 	| 34.0 	| 0.592 	| 3000 	| 64505 	| 1.000 |
| newstest2014-fren.fra-eng 	| 38.0 	| 0.633 	| 3003 	| 70708 	| 1.000 |
| Tatoeba-test.fra-eng 	| 57.9 	| 0.724 	| 10000 	| 77174 	| 0.981 |

# opus-2021-02-22.zip

* dataset: opus
* model: transformer-align
* source language(s): fra
* target language(s): eng
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-22.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-22.zip)
* test set translations: [opus-2021-02-22.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-22.test.txt)
* test set scores: [opus-2021-02-22.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opus-2021-02-22.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newsdiscussdev2015-enfr.fra-eng 	| 34.4 	| 0.587 	| 1500 	| 27759 	| 0.960 |
| newsdiscusstest2015-enfr.fra-eng 	| 39.7 	| 0.621 	| 1500 	| 26995 	| 0.993 |
| newssyscomb2009.fra-eng 	| 31.1 	| 0.575 	| 502 	| 11821 	| 0.999 |
| news-test2008.fra-eng 	| 26.5 	| 0.544 	| 2051 	| 49380 	| 1.000 |
| newstest2009.fra-eng 	| 30.5 	| 0.572 	| 2525 	| 65402 	| 1.000 |
| newstest2010.fra-eng 	| 32.7 	| 0.593 	| 2489 	| 61724 	| 1.000 |
| newstest2011.fra-eng 	| 33.1 	| 0.598 	| 3003 	| 74681 	| 1.000 |
| newstest2012.fra-eng 	| 33.2 	| 0.593 	| 3003 	| 72812 	| 1.000 |
| newstest2013.fra-eng 	| 34.0 	| 0.592 	| 3000 	| 64505 	| 1.000 |
| newstest2014-fren.fra-eng 	| 38.4 	| 0.636 	| 3003 	| 70708 	| 1.000 |
| Tatoeba-test.fra-eng 	| 57.8 	| 0.723 	| 10000 	| 77174 	| 0.983 |

