# opus-2021-01-03.zip

* dataset: opus
* model: transformer
* source language(s): deu
* target language(s): fin
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-01-03.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-01-03.zip)
* test set translations: [opus-2021-01-03.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-01-03.test.txt)
* test set scores: [opus-2021-01-03.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-01-03.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| goethe-institute-test1-deufin.deu.fin 	| 18.6 	| 0.501 |
| goethe-institute-test2-deufin.deu.fin 	| 18.3 	| 0.498 |
| Tatoeba-test.deu.fin 	| 40.1 	| 0.634 |
| Tatoeba-test.deu-fin.deu.fin 	| 40.1 	| 0.634 |








# opus-2021-02-16.zip

* dataset: opus
* model: transformer-align
* source language(s): deu
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-16.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-16.zip)
* test set translations: [opus-2021-02-16.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-16.test.txt)
* test set scores: [opus-2021-02-16.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-16.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.deu-fin 	| 40.3 	| 0.634 	| 2500 	| 14145 	| 0.944 |








# opus-2021-02-17.zip

* dataset: opus
* model: transformer-align
* source language(s): deu
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-17.zip)
* test set translations: [opus-2021-02-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-17.test.txt)
* test set scores: [opus-2021-02-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-17.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| goethe-institute-test1.deu-fin 	| 18.5 	| 0.499 	| 2000 	| 27070 	| 0.935 |
| goethe-institute-test2.deu-fin 	| 18.0 	| 0.496 	| 2000 	| 27014 	| 0.929 |
| Tatoeba-test.deu-fin 	| 40.4 	| 0.636 	| 2500 	| 14145 	| 0.947 |








# opus-2021-02-18.zip

* dataset: opus
* model: transformer-align
* source language(s): deu
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-18.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-18.zip)
* test set translations: [opus-2021-02-18.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-18.test.txt)
* test set scores: [opus-2021-02-18.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus-2021-02-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| goethe-institute-test1.deu-fin 	| 18.7 	| 0.501 	| 2000 	| 27070 	| 0.933 |
| goethe-institute-test2.deu-fin 	| 18.0 	| 0.497 	| 2000 	| 27014 	| 0.926 |
| Tatoeba-test.deu-fin 	| 40.2 	| 0.635 	| 2500 	| 14145 	| 0.948 |








# opus+bt-2021-03-08.zip

* dataset: opus+bt
* model: transformer-align
* source language(s): deu
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus+bt-2021-03-08.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus+bt-2021-03-08.zip)
* test set translations: [opus+bt-2021-03-08.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus+bt-2021-03-08.test.txt)
* test set scores: [opus+bt-2021-03-08.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opus+bt-2021-03-08.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| goethe-institute-test1.deu-fin 	| 20.7 	| 0.528 	| 2000 	| 27070 	| 0.946 |
| goethe-institute-test2.deu-fin 	| 20.0 	| 0.523 	| 2000 	| 27014 	| 0.939 |
| Tatoeba-test.deu-fin 	| 41.1 	| 0.645 	| 2500 	| 14145 	| 0.951 |


# opusTCv20210807+bt-2021-09-10.zip

* dataset: opusTCv20210807+bt
* model: transformer-align
* source language(s): deu
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-09-10.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opusTCv20210807+bt-2021-09-10.zip)
* test set translations: [opusTCv20210807+bt-2021-09-10.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opusTCv20210807+bt-2021-09-10.test.txt)
* test set scores: [opusTCv20210807+bt-2021-09-10.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/deu-fin/opusTCv20210807+bt-2021-09-10.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| goethe-institute-test1.deu-fin 	| 21.6 	| 0.536 	| 2000 	| 27070 	| 0.952 |
| goethe-institute-test2.deu-fin 	| 21.4 	| 0.535 	| 2000 	| 27014 	| 0.948 |
| Tatoeba-test-v2021-08-07.deu-fin 	| 41.9 	| 0.652 	| 2647 	| 15024 	| 0.957 |

