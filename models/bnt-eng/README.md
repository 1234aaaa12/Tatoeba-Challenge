# opus-2020-06-28.zip

* dataset: opus
* model: transformer
* source language(s): kdx kin lin lug nya run sna swh toi_Latn tso umb xho zul
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-06-28.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-06-28.zip)
* test set translations: [opus-2020-06-28.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-06-28.test.txt)
* test set scores: [opus-2020-06-28.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-06-28.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.kdx-eng.kdx.eng 	| 11.9 	| 0.285 |
| Tatoeba-test.kin-eng.kin.eng 	| 22.3 	| 0.422 |
| Tatoeba-test.lin-eng.lin.eng 	| 10.8 	| 0.238 |
| Tatoeba-test.lug-eng.lug.eng 	| 3.6 	| 0.135 |
| Tatoeba-test.multi.eng 	| 25.5 	| 0.424 |
| Tatoeba-test.nya-eng.nya.eng 	| 41.5 	| 0.528 |
| Tatoeba-test.run-eng.run.eng 	| 24.7 	| 0.419 |
| Tatoeba-test.sna-eng.sna.eng 	| 24.3 	| 0.417 |
| Tatoeba-test.swa-eng.swa.eng 	| 4.9 	| 0.203 |
| Tatoeba-test.toi-eng.toi.eng 	| 5.5 	| 0.160 |
| Tatoeba-test.tso-eng.tso.eng 	| 100.0 	| 1.000 |
| Tatoeba-test.umb-eng.umb.eng 	| 7.1 	| 0.209 |
| Tatoeba-test.xho-eng.xho.eng 	| 35.4 	| 0.516 |
| Tatoeba-test.zul-eng.zul.eng 	| 52.9 	| 0.659 |

# opus-2020-07-04.zip

* dataset: opus
* model: transformer
* source language(s): kdx kin lin lug nya run sna toi_Latn tso umb xho zul
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-04.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-07-04.zip)
* test set translations: [opus-2020-07-04.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-07-04.test.txt)
* test set scores: [opus-2020-07-04.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-07-04.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.kdx-eng.kdx.eng 	| 4.2 	| 0.198 |
| Tatoeba-test.kin-eng.kin.eng 	| 24.0 	| 0.417 |
| Tatoeba-test.lin-eng.lin.eng 	| 8.1 	| 0.254 |
| Tatoeba-test.lug-eng.lug.eng 	| 3.4 	| 0.141 |
| Tatoeba-test.multi.eng 	| 26.3 	| 0.433 |
| Tatoeba-test.nya-eng.nya.eng 	| 29.1 	| 0.485 |
| Tatoeba-test.run-eng.run.eng 	| 26.4 	| 0.433 |
| Tatoeba-test.sna-eng.sna.eng 	| 24.4 	| 0.400 |
| Tatoeba-test.toi-eng.toi.eng 	| 5.8 	| 0.142 |
| Tatoeba-test.tso-eng.tso.eng 	| 79.7 	| 0.852 |
| Tatoeba-test.umb-eng.umb.eng 	| 4.8 	| 0.215 |
| Tatoeba-test.xho-eng.xho.eng 	| 35.4 	| 0.523 |
| Tatoeba-test.zul-eng.zul.eng 	| 45.6 	| 0.577 |

# opus-2020-07-14.zip

* dataset: opus
* model: transformer
* source language(s): kin lin lug nya run sna swh toi_Latn tso umb xho zul
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-14.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-07-14.zip)
* test set translations: [opus-2020-07-14.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-07-14.test.txt)
* test set scores: [opus-2020-07-14.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/bnt-eng/opus-2020-07-14.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.kin-eng.kin.eng 	| 29.1 	| 0.472 |
| Tatoeba-test.lin-eng.lin.eng 	| 5.7 	| 0.239 |
| Tatoeba-test.lug-eng.lug.eng 	| 8.2 	| 0.277 |
| Tatoeba-test.multi.eng 	| 22.2 	| 0.386 |
| Tatoeba-test.nya-eng.nya.eng 	| 35.0 	| 0.516 |
| Tatoeba-test.run-eng.run.eng 	| 26.0 	| 0.425 |
| Tatoeba-test.sna-eng.sna.eng 	| 15.9 	| 0.374 |
| Tatoeba-test.toi-eng.toi.eng 	| 5.0 	| 0.094 |
| Tatoeba-test.tso-eng.tso.eng 	| 100.0 	| 1.000 |
| Tatoeba-test.umb-eng.umb.eng 	| 5.4 	| 0.199 |
| Tatoeba-test.xho-eng.xho.eng 	| 37.1 	| 0.547 |
| Tatoeba-test.zul-eng.zul.eng 	| 47.1 	| 0.606 |

