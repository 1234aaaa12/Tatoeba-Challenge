# opus-2020-06-28.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kkt kpv krl liv_Latn mdf mhr myv udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-06-28.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-06-28.zip)
* test set translations: [opus-2020-06-28.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-06-28.test.txt)
* test set scores: [opus-2020-06-28.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-06-28.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 21.3 	| 0.496 |
| newsdev2018-enet-esteng.est.eng 	| 24.6 	| 0.526 |
| newssyscomb2009-huneng.hun.eng 	| 19.6 	| 0.480 |
| newstest2009-huneng.hun.eng 	| 18.4 	| 0.473 |
| newstest2015-enfi-fineng.fin.eng 	| 21.9 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 24.0 	| 0.526 |
| newstest2017-enfi-fineng.fin.eng 	| 26.3 	| 0.541 |
| newstest2018-enet-esteng.est.eng 	| 24.9 	| 0.533 |
| newstest2018-enfi-fineng.fin.eng 	| 20.1 	| 0.479 |
| newstest2019-fien-fineng.fin.eng 	| 23.2 	| 0.510 |
| newstestB2016-enfi-fineng.fin.eng 	| 20.0 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.8 	| 0.510 |
| newstestB2017-fien-fineng.fin.eng 	| 22.8 	| 0.510 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.4 	| 0.168 |
| Tatoeba-test.est-eng.est.eng 	| 53.1 	| 0.689 |
| Tatoeba-test.fin-eng.fin.eng 	| 46.6 	| 0.642 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 8.1 	| 0.368 |
| Tatoeba-test.hun-eng.hun.eng 	| 45.0 	| 0.622 |
| Tatoeba-test.izh-eng.izh.eng 	| 65.1 	| 0.795 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 1.1 	| 0.143 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.8 	| 0.102 |
| Tatoeba-test.krl-eng.krl.eng 	| 29.7 	| 0.453 |
| Tatoeba-test.liv-eng.liv.eng 	| 2.2 	| 0.091 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.2 	| 0.131 |
| Tatoeba-test.multi.eng 	| 45.8 	| 0.630 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.6 	| 0.118 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.7 	| 0.176 |


# opus-2020-07-26.zip

* dataset: opus
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-26.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-26.zip)
* test set translations: [opus-2020-07-26.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-26.test.txt)
* test set scores: [opus-2020-07-26.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus-2020-07-26.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 21.1 	| 0.493 |
| newsdev2018-enet-esteng.est.eng 	| 24.3 	| 0.522 |
| newssyscomb2009-huneng.hun.eng 	| 19.0 	| 0.476 |
| newstest2009-huneng.hun.eng 	| 18.1 	| 0.470 |
| newstest2015-enfi-fineng.fin.eng 	| 22.4 	| 0.502 |
| newstest2016-enfi-fineng.fin.eng 	| 23.7 	| 0.523 |
| newstest2017-enfi-fineng.fin.eng 	| 26.2 	| 0.538 |
| newstest2018-enet-esteng.est.eng 	| 24.8 	| 0.530 |
| newstest2018-enfi-fineng.fin.eng 	| 19.5 	| 0.475 |
| newstest2019-fien-fineng.fin.eng 	| 23.1 	| 0.509 |
| newstestB2016-enfi-fineng.fin.eng 	| 19.8 	| 0.485 |
| newstestB2017-enfi-fineng.fin.eng 	| 22.7 	| 0.508 |
| newstestB2017-fien-fineng.fin.eng 	| 22.7 	| 0.508 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.1 	| 0.159 |
| Tatoeba-test.est-eng.est.eng 	| 52.9 	| 0.682 |
| Tatoeba-test.fin-eng.fin.eng 	| 46.3 	| 0.639 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 8.0 	| 0.376 |
| Tatoeba-test.hun-eng.hun.eng 	| 44.6 	| 0.619 |
| Tatoeba-test.izh-eng.izh.eng 	| 38.4 	| 0.608 |
| Tatoeba-test.kkt-eng.kkt.eng 	| 0.5 	| 0.142 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.6 	| 0.081 |
| Tatoeba-test.krl-eng.krl.eng 	| 32.7 	| 0.453 |
| Tatoeba-test.liv-eng.liv.eng 	| 1.4 	| 0.080 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.2 	| 0.119 |
| Tatoeba-test.multi.eng 	| 45.4 	| 0.626 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.4 	| 0.109 |
| Tatoeba-test.sma-eng.sma.eng 	| 2.3 	| 0.116 |
| Tatoeba-test.sme-eng.sme.eng 	| 8.3 	| 0.204 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.8 	| 0.148 |


# opus2m-2020-07-31.zip

* dataset: opus2m
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus2m-2020-07-31.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus2m-2020-07-31.zip)
* test set translations: [opus2m-2020-07-31.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus2m-2020-07-31.test.txt)
* test set scores: [opus2m-2020-07-31.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus2m-2020-07-31.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 22.9 	| 0.513 |
| newsdev2018-enet-esteng.est.eng 	| 26.3 	| 0.543 |
| newssyscomb2009-huneng.hun.eng 	| 21.2 	| 0.494 |
| newstest2009-huneng.hun.eng 	| 19.8 	| 0.486 |
| newstest2015-enfi-fineng.fin.eng 	| 24.1 	| 0.521 |
| newstest2016-enfi-fineng.fin.eng 	| 25.6 	| 0.541 |
| newstest2017-enfi-fineng.fin.eng 	| 28.7 	| 0.560 |
| newstest2018-enet-esteng.est.eng 	| 26.5 	| 0.549 |
| newstest2018-enfi-fineng.fin.eng 	| 21.2 	| 0.490 |
| newstest2019-fien-fineng.fin.eng 	| 25.6 	| 0.533 |
| newstestB2016-enfi-fineng.fin.eng 	| 21.6 	| 0.500 |
| newstestB2017-enfi-fineng.fin.eng 	| 24.3 	| 0.526 |
| newstestB2017-fien-fineng.fin.eng 	| 24.3 	| 0.526 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.2 	| 0.163 |
| Tatoeba-test.est-eng.est.eng 	| 55.3 	| 0.706 |
| Tatoeba-test.fin-eng.fin.eng 	| 48.7 	| 0.660 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 11.5 	| 0.384 |
| Tatoeba-test.hun-eng.hun.eng 	| 46.7 	| 0.638 |
| Tatoeba-test.izh-eng.izh.eng 	| 48.3 	| 0.678 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.7 	| 0.113 |
| Tatoeba-test.krl-eng.krl.eng 	| 36.1 	| 0.485 |
| Tatoeba-test.liv-eng.liv.eng 	| 2.1 	| 0.086 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 0.9 	| 0.120 |
| Tatoeba-test.multi.eng 	| 47.8 	| 0.648 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.7 	| 0.121 |
| Tatoeba-test.sma-eng.sma.eng 	| 1.7 	| 0.101 |
| Tatoeba-test.sme-eng.sme.eng 	| 7.8 	| 0.229 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.9 	| 0.166 |


# opus4m-2020-08-12.zip

* dataset: opus4m
* model: transformer
* source language(s): est fin fkv_Latn hun izh kpv krl liv_Latn mdf mhr myv sma sme udm vro
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus4m-2020-08-12.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus4m-2020-08-12.zip)
* test set translations: [opus4m-2020-08-12.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus4m-2020-08-12.test.txt)
* test set scores: [opus4m-2020-08-12.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus4m-2020-08-12.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newsdev2015-enfi-fineng.fin.eng 	| 23.2 	| 0.518 |
| newsdev2018-enet-esteng.est.eng 	| 27.4 	| 0.552 |
| newssyscomb2009-huneng.hun.eng 	| 21.5 	| 0.499 |
| newstest2009-huneng.hun.eng 	| 20.6 	| 0.493 |
| newstest2015-enfi-fineng.fin.eng 	| 24.9 	| 0.528 |
| newstest2016-enfi-fineng.fin.eng 	| 26.4 	| 0.549 |
| newstest2017-enfi-fineng.fin.eng 	| 29.4 	| 0.569 |
| newstest2018-enet-esteng.est.eng 	| 27.7 	| 0.560 |
| newstest2018-enfi-fineng.fin.eng 	| 21.9 	| 0.497 |
| newstest2019-fien-fineng.fin.eng 	| 26.5 	| 0.541 |
| newstestB2016-enfi-fineng.fin.eng 	| 22.3 	| 0.508 |
| newstestB2017-enfi-fineng.fin.eng 	| 24.9 	| 0.535 |
| newstestB2017-fien-fineng.fin.eng 	| 24.9 	| 0.535 |
| Tatoeba-test.chm-eng.chm.eng 	| 1.1 	| 0.166 |
| Tatoeba-test.est-eng.est.eng 	| 55.1 	| 0.706 |
| Tatoeba-test.fin-eng.fin.eng 	| 49.3 	| 0.665 |
| Tatoeba-test.fkv-eng.fkv.eng 	| 10.6 	| 0.391 |
| Tatoeba-test.hun-eng.hun.eng 	| 47.8 	| 0.647 |
| Tatoeba-test.izh-eng.izh.eng 	| 48.3 	| 0.678 |
| Tatoeba-test.kom-eng.kom.eng 	| 0.6 	| 0.105 |
| Tatoeba-test.krl-eng.krl.eng 	| 35.4 	| 0.491 |
| Tatoeba-test.liv-eng.liv.eng 	| 1.4 	| 0.072 |
| Tatoeba-test.mdf-eng.mdf.eng 	| 1.3 	| 0.123 |
| Tatoeba-test.multi.eng 	| 48.7 	| 0.655 |
| Tatoeba-test.myv-eng.myv.eng 	| 0.3 	| 0.114 |
| Tatoeba-test.sma-eng.sma.eng 	| 2.3 	| 0.105 |
| Tatoeba-test.sme-eng.sme.eng 	| 8.7 	| 0.251 |
| Tatoeba-test.udm-eng.udm.eng 	| 0.9 	| 0.119 |


# opus1m+bt-2021-05-01.zip

* dataset: opus1m+bt
* model: transformer-align
* source language(s): est fin fkv hun izh kom kpv krl liv mdf mhr mrj myv sma sme udm vro
* target language(s): eng
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus1m+bt-2021-05-01.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus1m+bt-2021-05-01.zip)
* test set translations: [opus1m+bt-2021-05-01.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus1m+bt-2021-05-01.test.txt)
* test set scores: [opus1m+bt-2021-05-01.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-eng/opus1m+bt-2021-05-01.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| newsdev2015-enfi.fin-eng 	| 21.2 	| 0.497 	| 1500 	| 32104 	| 0.998 |
| newsdev2018-enet.est-eng 	| 24.7 	| 0.529 	| 2000 	| 43194 	| 1.000 |
| newssyscomb2009.hun-eng 	| 19.4 	| 0.479 	| 502 	| 11821 	| 0.958 |
| newstest2009.hun-eng 	| 18.3 	| 0.472 	| 2525 	| 65402 	| 0.957 |
| newstest2015-enfi.fin-eng 	| 22.5 	| 0.507 	| 1370 	| 27356 	| 0.988 |
| newstest2016-enfi.fin-eng 	| 24.2 	| 0.526 	| 3000 	| 63043 	| 1.000 |
| newstest2017-enfi.fin-eng 	| 26.6 	| 0.542 	| 3002 	| 61936 	| 0.995 |
| newstest2018-enet.est-eng 	| 25.1 	| 0.535 	| 2000 	| 45521 	| 1.000 |
| newstest2018-enfi.fin-eng 	| 19.6 	| 0.476 	| 3000 	| 62325 	| 0.985 |
| newstest2019-fien.fin-eng 	| 23.7 	| 0.516 	| 1996 	| 36227 	| 0.999 |
| newstestB2016-enfi.fin-eng 	| 20.1 	| 0.487 	| 3000 	| 63043 	| 0.992 |
| newstestB2017-enfi.fin-eng 	| 22.8 	| 0.511 	| 3002 	| 61936 	| 1.000 |
| newstestB2017-fien.fin-eng 	| 22.8 	| 0.511 	| 3002 	| 61936 	| 1.000 |
| Tatoeba-test.chm-eng 	| 1.3 	| 0.167 	| 71 	| 470 	| 1.000 |
| Tatoeba-test.est-eng 	| 52.5 	| 0.687 	| 1359 	| 8804 	| 0.976 |
| Tatoeba-test.fin-eng 	| 46.5 	| 0.643 	| 10000 	| 74643 	| 0.989 |
| Tatoeba-test.fkv-eng 	| 11.0 	| 0.393 	| 71 	| 652 	| 1.000 |
| Tatoeba-test.hun-eng 	| 44.9 	| 0.622 	| 10000 	| 69322 	| 0.976 |
| Tatoeba-test.izh-eng 	| 44.6 	| 0.702 	| 6 	| 23 	| 1.000 |
| Tatoeba-test.kom-eng 	| 0.9 	| 0.102 	| 15 	| 50 	| 1.000 |
| Tatoeba-test.krl-eng 	| 33.6 	| 0.487 	| 149 	| 710 	| 1.000 |
| Tatoeba-test.liv-eng 	| 2.2 	| 0.079 	| 33 	| 185 	| 0.933 |
| Tatoeba-test.mdf-eng 	| 1.3 	| 0.115 	| 7 	| 36 	| 1.000 |
| Tatoeba-test.multi-eng 	| 45.7 	| 0.630 	| 10000 	| 71405 	| 0.989 |
| Tatoeba-test.myv-eng 	| 0.4 	| 0.122 	| 25 	| 113 	| 1.000 |
| Tatoeba-test.sma-eng 	| 2.4 	| 0.111 	| 47 	| 219 	| 0.948 |
| Tatoeba-test.sme-eng 	| 9.3 	| 0.241 	| 62 	| 300 	| 1.000 |
| Tatoeba-test.udm-eng 	| 0.9 	| 0.170 	| 10 	| 49 	| 1.000 |
| Tatoeba-test.vro-eng 	| 29.7 	| 0.381 	| 5 	| 44 	| 0.929 |

