# opus-2021-02-16.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-16.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.zip)
* test set translations: [opus-2021-02-16.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.test.txt)
* test set scores: [opus-2021-02-16.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.swe-fin 	| 44.6 	| 0.668 	| 2500 	| 13711 	| 0.951 |

# opus-2021-02-17.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.zip)
* test set translations: [opus-2021-02-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.test.txt)
* test set scores: [opus-2021-02-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 26.3 	| 0.618 	| 523 	| 7638 	| 0.998 |
| Tatoeba-test.swe-fin 	| 44.7 	| 0.670 	| 2500 	| 13711 	| 0.954 |

# opus-2021-02-18.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-18.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.zip)
* test set translations: [opus-2021-02-18.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.test.txt)
* test set scores: [opus-2021-02-18.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 25.8 	| 0.614 	| 523 	| 7638 	| 0.998 |
| Tatoeba-test.swe-fin 	| 44.4 	| 0.669 	| 2500 	| 13711 	| 0.954 |

