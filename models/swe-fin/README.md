# opus-2021-02-16.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-16.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.zip)
* test set translations: [opus-2021-02-16.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.test.txt)
* test set scores: [opus-2021-02-16.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-16.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.swe-fin 	| 44.6 	| 0.668 	| 2500 	| 13711 	| 0.951 |


# opus-2021-02-17.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.zip)
* test set translations: [opus-2021-02-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.test.txt)
* test set scores: [opus-2021-02-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-17.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 26.3 	| 0.618 	| 523 	| 7638 	| 0.998 |
| Tatoeba-test.swe-fin 	| 44.7 	| 0.670 	| 2500 	| 13711 	| 0.954 |


# opus-2021-02-18.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-18.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.zip)
* test set translations: [opus-2021-02-18.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.test.txt)
* test set scores: [opus-2021-02-18.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 25.8 	| 0.614 	| 523 	| 7638 	| 0.998 |
| Tatoeba-test.swe-fin 	| 44.4 	| 0.669 	| 2500 	| 13711 	| 0.954 |


# opus-2021-02-22.zip

* dataset: opus
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-22.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-22.zip)
* test set translations: [opus-2021-02-22.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-22.test.txt)
* test set scores: [opus-2021-02-22.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opus-2021-02-22.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 26.3 	| 0.615 	| 523 	| 7638 	| 0.997 |
| MeMAD-YLE-test.FIH-SWE.swe-fin 	| 12.2 	| 0.427 	| 625 	| 6075 	| 0.868 |
| MeMAD-YLE-test.FIN-SWE.swe-fin 	| 20.8 	| 0.492 	| 1252 	| 10812 	| 0.976 |
| MeMAD-YLE-test.FIN-SWH.swe-fin 	| 15.9 	| 0.444 	| 2837 	| 23153 	| 0.942 |
| Tatoeba-test.swe-fin 	| 44.5 	| 0.668 	| 2500 	| 13711 	| 0.956 |


# opusTCv20210807+bt-2021-08-26.zip

* dataset: opusTCv20210807+bt
* model: transformer-align
* source language(s): swe
* target language(s): fin
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807+bt-2021-08-26.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-08-26.zip)
* test set translations: [opusTCv20210807+bt-2021-08-26.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-08-26.test.txt)
* test set scores: [opusTCv20210807+bt-2021-08-26.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/swe-fin/opusTCv20210807+bt-2021-08-26.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| fiskmo_testset.swe-fin 	| 30.2 	| 0.648 	| 523 	| 7638 	| 0.983 |
| Tatoeba-test-v2021-08-07.swe-fin 	| 45.8 	| 0.681 	| 2841 	| 15621 	| 0.958 |

