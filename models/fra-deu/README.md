# opus-2021-01-03.zip

* dataset: opus
* model: transformer
* source language(s): fra
* target language(s): deu
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-01-03.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-01-03.zip)
* test set translations: [opus-2021-01-03.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-01-03.test.txt)
* test set scores: [opus-2021-01-03.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-01-03.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| euelections_dev2019.fr-de-fradeu.fra.deu 	| 26.4 	| 0.572 |
| newssyscomb2009-fradeu.fra.deu 	| 22.5 	| 0.528 |
| news-test2008-fradeu.fra.deu 	| 22.2 	| 0.527 |
| newstest2009-fradeu.fra.deu 	| 22.2 	| 0.525 |
| newstest2010-fradeu.fra.deu 	| 23.1 	| 0.532 |
| newstest2011-fradeu.fra.deu 	| 21.9 	| 0.522 |
| newstest2012-fradeu.fra.deu 	| 22.9 	| 0.520 |
| newstest2013-fradeu.fra.deu 	| 24.7 	| 0.537 |
| newstest2019-frde-fradeu.fra.deu 	| 27.6 	| 0.595 |
| Tatoeba-test.fra.deu 	| 49.5 	| 0.678 |
| Tatoeba-test.fra-deu.fra.deu 	| 49.5 	| 0.678 |


# opus-2021-02-18.zip

* dataset: opus
* model: transformer-align
* source language(s): fra
* target language(s): deu
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-18.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-02-18.zip)
* test set translations: [opus-2021-02-18.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-02-18.test.txt)
* test set scores: [opus-2021-02-18.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-02-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| euelections_dev2019.fr-de.fra-deu 	| 25.6 	| 0.567 	| 1512 	| 33478 	| 1.000 |
| newssyscomb2009.fra-deu 	| 22.0 	| 0.523 	| 502 	| 11271 	| 0.999 |
| news-test2008.fra-deu 	| 21.6 	| 0.521 	| 2051 	| 47427 	| 1.000 |
| newstest2009.fra-deu 	| 21.5 	| 0.519 	| 2525 	| 62816 	| 1.000 |
| newstest2010.fra-deu 	| 22.5 	| 0.526 	| 2489 	| 61511 	| 1.000 |
| newstest2011.fra-deu 	| 21.1 	| 0.516 	| 3003 	| 72981 	| 1.000 |
| newstest2012.fra-deu 	| 22.4 	| 0.515 	| 3003 	| 72886 	| 1.000 |
| newstest2013.fra-deu 	| 23.9 	| 0.532 	| 3000 	| 63737 	| 1.000 |
| newstest2019-frde.fra-deu 	| 27.3 	| 0.593 	| 1701 	| 36571 	| 1.000 |
| Tatoeba-test.fra-deu 	| 48.2 	| 0.668 	| 10000 	| 80271 	| 0.996 |


# opus-2021-02-22.zip

* dataset: opus
* model: transformer-align
* source language(s): fra
* target language(s): deu
* model: transformer-align
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2021-02-22.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-02-22.zip)
* test set translations: [opus-2021-02-22.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-02-22.test.txt)
* test set scores: [opus-2021-02-22.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opus-2021-02-22.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| euelections_dev2019.fr-de.fra-deu 	| 26.0 	| 0.571 	| 1512 	| 33478 	| 1.000 |
| newssyscomb2009.fra-deu 	| 23.2 	| 0.529 	| 502 	| 11271 	| 0.998 |
| news-test2008.fra-deu 	| 21.8 	| 0.523 	| 2051 	| 47427 	| 1.000 |
| newstest2009.fra-deu 	| 21.7 	| 0.522 	| 2525 	| 62816 	| 1.000 |
| newstest2010.fra-deu 	| 22.8 	| 0.529 	| 2489 	| 61511 	| 0.998 |
| newstest2011.fra-deu 	| 21.4 	| 0.518 	| 3003 	| 72981 	| 1.000 |
| newstest2012.fra-deu 	| 22.5 	| 0.517 	| 3003 	| 72886 	| 0.999 |
| newstest2013.fra-deu 	| 24.1 	| 0.535 	| 3000 	| 63737 	| 1.000 |
| newstest2019-frde.fra-deu 	| 27.9 	| 0.598 	| 1701 	| 36571 	| 1.000 |
| Tatoeba-test.fra-deu 	| 48.7 	| 0.671 	| 10000 	| 80271 	| 0.994 |


# opusTCv20210807_transformer-big_2022-07-22.zip

* dataset: opusTCv20210807
* model: transformer-big
* source language(s): fra
* target language(s): deu
* raw source language(s): fra
* raw target language(s): deu
* model: transformer-big
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opusTCv20210807_transformer-big_2022-07-22.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opusTCv20210807_transformer-big_2022-07-22.zip)
* test set translations: [opusTCv20210807_transformer-big_2022-07-22.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opusTCv20210807_transformer-big_2022-07-22.test.txt)
* test set scores: [opusTCv20210807_transformer-big_2022-07-22.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/fra-deu/opusTCv20210807_transformer-big_2022-07-22.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| euelections_dev2019.fr-de.fra-deu 	| 30.2 	| 0.59501 	| 1512 	| 33478 	| 1.000 |
| newssyscomb2009.fra-deu 	| 24.2 	| 0.53970 	| 502 	| 11271 	| 0.974 |
| news-test2008.fra-deu 	| 24.3 	| 0.54008 	| 2051 	| 47427 	| 1.000 |
| newstest2009.fra-deu 	| 23.7 	| 0.53423 	| 2525 	| 62816 	| 0.990 |
| newstest2010.fra-deu 	| 24.8 	| 0.54376 	| 2489 	| 61511 	| 0.976 |
| newstest2011.fra-deu 	| 24.0 	| 0.53647 	| 3003 	| 72981 	| 1.000 |
| newstest2012.fra-deu 	| 24.9 	| 0.53552 	| 3003 	| 72886 	| 0.982 |
| newstest2013.fra-deu 	| 27.0 	| 0.55066 	| 3000 	| 63737 	| 1.000 |
| newstest2019-frde.fra-deu 	| 32.1 	| 0.62265 	| 1701 	| 36571 	| 1.000 |
| Tatoeba-test-v2021-08-07.fra-deu 	| 52.1 	| 0.70133 	| 10000 	| 81031 	| 0.996 |

