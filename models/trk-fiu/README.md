# opus-2021-02-10.zip

* dataset: opus
* model: transformer
* source language(s): alt aze bak chg chv crh gag kaa kaz kir kjh krc kum nog ota otk sah tat tuk tur tyv uig uzb
* target language(s): chm est fin fkv hun izh kom krl liv mdf myv olo sma sme udm vep
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* download: [opus-2021-02-10.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-10.zip)
* test set translations: [opus-2021-02-10.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-10.test.txt)
* test set scores: [opus-2021-02-10.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-10.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| Tatoeba-test.bak-est.bak.est 	| 4.0 	| 0.161 |
| Tatoeba-test.kaz-est.kaz.est 	| 32.5 	| 0.439 |
| Tatoeba-test.multi.multi 	| 26.4 	| 0.513 |
| Tatoeba-test.ota-hun.ota.hun 	| 26.9 	| 0.231 |
| Tatoeba-test.tat-chm.tat.chm 	| 2.7 	| 0.005 |
| Tatoeba-test.tat-est.tat.est 	| 4.7 	| 0.271 |
| Tatoeba-test.tat-fin.tat.fin 	| 3.6 	| 0.225 |
| Tatoeba-test.tat-hun.tat.hun 	| 13.5 	| 0.333 |
| Tatoeba-test.tur-est.tur.est 	| 42.5 	| 0.563 |
| Tatoeba-test.tur-fin.tur.fin 	| 25.9 	| 0.512 |
| Tatoeba-test.tur-hun.tur.hun 	| 27.7 	| 0.524 |
| Tatoeba-test.uzb-est.uzb.est 	| 35.0 	| 0.435 |





# opus-2021-02-17.zip

* dataset: opus
* model: transformer
* source language(s): bak kaz ota tat tur uzb
* target language(s): est fin hun mhr
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* valid language labels: >>est<< >>fin<< >>hun<<
* download: [opus-2021-02-17.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-17.zip)
* test set translations: [opus-2021-02-17.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-17.test.txt)
* test set scores: [opus-2021-02-17.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-17.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.multi-multi 	| 26.4 	| 0.513 	| 2798 	| 15728 	| 0.942 |





# opus-2021-02-18.zip

* dataset: opus
* model: transformer
* source language(s): bak kaz ota tat tur uzb
* target language(s): est fin hun mhr
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* valid language labels: >>est<< >>fin<< >>hun<<
* download: [opus-2021-02-18.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-18.zip)
* test set translations: [opus-2021-02-18.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-18.test.txt)
* test set scores: [opus-2021-02-18.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-18.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.multi-multi 	| 26.4 	| 0.513 	| 2798 	| 15728 	| 0.942 |





# opus-2021-02-19.zip

* dataset: opus
* model: transformer
* source language(s): bak kaz ota tat tur uzb
* target language(s): est fin hun mhr
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* a sentence initial language token is required in the form of `>>id<<` (id = valid target language ID)
* valid language labels: >>est<< >>fin<< >>hun<<
* download: [opus-2021-02-19.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-19.zip)
* test set translations: [opus-2021-02-19.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-19.test.txt)
* test set scores: [opus-2021-02-19.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/trk-fiu/opus-2021-02-19.eval.txt)

## Benchmarks

| testset | BLEU  | chr-F | #sent | #words | BP |
|---------|-------|-------|-------|--------|----|
| Tatoeba-test.bak-est 	| 4.0 	| 0.161 	| 1 	| 6 	| 1.000 |
| Tatoeba-test.kaz-est 	| 32.5 	| 0.439 	| 1 	| 6 	| 1.000 |
| Tatoeba-test.multi-multi 	| 26.4 	| 0.513 	| 2798 	| 15728 	| 0.942 |
| Tatoeba-test.ota_Arab-hun 	| 0.0 	| 0.000 	| 1 	| 3 	| 0.607 |
| Tatoeba-test.ota-hun 	| 26.9 	| 0.231 	| 2 	| 6 	| 1.000 |
| Tatoeba-test.ota_Latn-hun 	| 31.9 	| 0.407 	| 1 	| 3 	| 1.000 |
| Tatoeba-test.tat-chm 	| 2.7 	| 0.005 	| 1 	| 12 	| 1.000 |
| Tatoeba-test.tat-est 	| 4.7 	| 0.271 	| 3 	| 17 	| 0.939 |
| Tatoeba-test.tat-fin 	| 3.6 	| 0.225 	| 6 	| 83 	| 0.568 |
| Tatoeba-test.tat-hun 	| 4.0 	| 0.265 	| 1 	| 8 	| 1.000 |
| Tatoeba-test.tat_Latn-est 	| 10.7 	| 0.213 	| 1 	| 5 	| 1.000 |
| Tatoeba-test.tat_Latn-fin 	| 1.0 	| 0.110 	| 1 	| 30 	| 0.178 |
| Tatoeba-test.tur-est 	| 42.5 	| 0.563 	| 21 	| 117 	| 0.873 |
| Tatoeba-test.tur-fin 	| 25.9 	| 0.512 	| 1796 	| 10455 	| 0.918 |
| Tatoeba-test.tur-hun 	| 27.7 	| 0.524 	| 965 	| 4994 	| 0.998 |
| Tatoeba-test.uzb-est 	| 35.0 	| 0.435 	| 1 	| 6 	| 0.819 |

