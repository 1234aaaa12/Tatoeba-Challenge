# opus-2020-06-27.zip

* dataset: opus
* model: transformer
* source language(s): afr ang_Latn deu enm_Latn frr fry gos gsw ksh ltz nds nld pdc sco stq swg yid
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-06-27.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-06-27.zip)
* test set translations: [opus-2020-06-27.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-06-27.test.txt)
* test set scores: [opus-2020-06-27.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-06-27.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newssyscomb2009-deueng.deu.eng 	| 26.2 	| 0.535 |
| news-test2008-deueng.deu.eng 	| 25.1 	| 0.528 |
| newstest2009-deueng.deu.eng 	| 24.4 	| 0.524 |
| newstest2010-deueng.deu.eng 	| 27.4 	| 0.560 |
| newstest2011-deueng.deu.eng 	| 24.7 	| 0.532 |
| newstest2012-deueng.deu.eng 	| 26.0 	| 0.542 |
| newstest2013-deueng.deu.eng 	| 28.9 	| 0.559 |
| newstest2014-deen-deueng.deu.eng 	| 29.5 	| 0.566 |
| newstest2015-ende-deueng.deu.eng 	| 30.6 	| 0.570 |
| newstest2016-ende-deueng.deu.eng 	| 35.7 	| 0.614 |
| newstest2017-ende-deueng.deu.eng 	| 31.5 	| 0.578 |
| newstest2018-ende-deueng.deu.eng 	| 38.7 	| 0.631 |
| newstest2019-deen-deueng.deu.eng 	| 35.1 	| 0.602 |
| Tatoeba-test.afr.eng 	| 46.8 	| 0.633 |
| Tatoeba-test.afr-eng.afr.eng 	| 61.1 	| 0.744 |
| Tatoeba-test.ang-eng.ang.eng 	| 6.4 	| 0.156 |
| Tatoeba-test.deu-eng.deu.eng 	| 47.1 	| 0.648 |
| Tatoeba-test.enm-eng.enm.eng 	| 15.8 	| 0.431 |
| Tatoeba-test.frr-eng.frr.eng 	| 14.1 	| 0.224 |
| Tatoeba-test.fry-eng.fry.eng 	| 24.6 	| 0.457 |
| Tatoeba-test.gos-eng.gos.eng 	| 13.4 	| 0.301 |
| Tatoeba-test.gsw-eng.gsw.eng 	| 12.5 	| 0.296 |
| Tatoeba-test.ksh-eng.ksh.eng 	| 8.2 	| 0.242 |
| Tatoeba-test.ltz-eng.ltz.eng 	| 28.6 	| 0.438 |
| Tatoeba-test.multi.eng 	| 46.8 	| 0.633 |
| Tatoeba-test.nds-eng.nds.eng 	| 29.7 	| 0.490 |
| Tatoeba-test.nld-eng.nld.eng 	| 56.9 	| 0.720 |
| Tatoeba-test.pdc-eng.pdc.eng 	| 26.5 	| 0.422 |
| Tatoeba-test.sco-eng.sco.eng 	| 31.3 	| 0.514 |
| Tatoeba-test.stq-eng.stq.eng 	| 20.8 	| 0.406 |
| Tatoeba-test.swg-eng.swg.eng 	| 12.2 	| 0.294 |
| Tatoeba-test.yid-eng.yid.eng 	| 14.3 	| 0.348 |

# opus-2020-07-04.zip

* dataset: opus
* model: transformer
* source language(s): afr ang_Latn deu enm_Latn frr fry gos gsw ksh ltz nds nld pdc sco stq swg yid
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-04.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-04.zip)
* test set translations: [opus-2020-07-04.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-04.test.txt)
* test set scores: [opus-2020-07-04.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-04.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newssyscomb2009-deueng.deu.eng 	| 26.7 	| 0.536 |
| news-test2008-deueng.deu.eng 	| 25.2 	| 0.529 |
| newstest2009-deueng.deu.eng 	| 24.5 	| 0.525 |
| newstest2010-deueng.deu.eng 	| 27.2 	| 0.559 |
| newstest2011-deueng.deu.eng 	| 24.9 	| 0.534 |
| newstest2012-deueng.deu.eng 	| 25.9 	| 0.543 |
| newstest2013-deueng.deu.eng 	| 28.8 	| 0.558 |
| newstest2014-deen-deueng.deu.eng 	| 29.5 	| 0.565 |
| newstest2015-ende-deueng.deu.eng 	| 30.6 	| 0.570 |
| newstest2016-ende-deueng.deu.eng 	| 36.1 	| 0.617 |
| newstest2017-ende-deueng.deu.eng 	| 31.7 	| 0.578 |
| newstest2018-ende-deueng.deu.eng 	| 38.8 	| 0.630 |
| newstest2019-deen-deueng.deu.eng 	| 34.9 	| 0.601 |
| Tatoeba-test.afr-eng.afr.eng 	| 61.3 	| 0.748 |
| Tatoeba-test.ang-eng.ang.eng 	| 6.4 	| 0.203 |
| Tatoeba-test.deu-eng.deu.eng 	| 47.5 	| 0.649 |
| Tatoeba-test.enm-eng.enm.eng 	| 15.9 	| 0.426 |
| Tatoeba-test.frr-eng.frr.eng 	| 6.1 	| 0.073 |
| Tatoeba-test.fry-eng.fry.eng 	| 25.5 	| 0.468 |
| Tatoeba-test.gos-eng.gos.eng 	| 12.5 	| 0.308 |
| Tatoeba-test.gsw-eng.gsw.eng 	| 8.5 	| 0.279 |
| Tatoeba-test.ksh-eng.ksh.eng 	| 8.4 	| 0.261 |
| Tatoeba-test.ltz-eng.ltz.eng 	| 27.3 	| 0.437 |
| Tatoeba-test.multi.eng 	| 47.5 	| 0.637 |
| Tatoeba-test.nds-eng.nds.eng 	| 30.1 	| 0.494 |
| Tatoeba-test.nld-eng.nld.eng 	| 57.5 	| 0.723 |
| Tatoeba-test.pdc-eng.pdc.eng 	| 28.9 	| 0.427 |
| Tatoeba-test.sco-eng.sco.eng 	| 45.3 	| 0.602 |
| Tatoeba-test.stq-eng.stq.eng 	| 20.1 	| 0.385 |
| Tatoeba-test.swg-eng.swg.eng 	| 13.8 	| 0.284 |
| Tatoeba-test.yid-eng.yid.eng 	| 14.2 	| 0.341 |

# opus-2020-07-14.zip

* dataset: opus
* model: transformer
* source language(s): afr ang_Latn deu enm_Latn frr fry gos gsw ksh ltz nds nld pdc sco stq swg yid
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-14.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-14.zip)
* test set translations: [opus-2020-07-14.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-14.test.txt)
* test set scores: [opus-2020-07-14.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-14.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newssyscomb2009-deueng.deu.eng 	| 26.7 	| 0.536 |
| news-test2008-deueng.deu.eng 	| 25.2 	| 0.529 |
| newstest2009-deueng.deu.eng 	| 24.5 	| 0.525 |
| newstest2010-deueng.deu.eng 	| 27.2 	| 0.559 |
| newstest2011-deueng.deu.eng 	| 24.9 	| 0.534 |
| newstest2012-deueng.deu.eng 	| 25.9 	| 0.543 |
| newstest2013-deueng.deu.eng 	| 28.8 	| 0.558 |
| newstest2014-deen-deueng.deu.eng 	| 29.5 	| 0.565 |
| newstest2015-ende-deueng.deu.eng 	| 30.6 	| 0.570 |
| newstest2016-ende-deueng.deu.eng 	| 36.1 	| 0.617 |
| newstest2017-ende-deueng.deu.eng 	| 31.7 	| 0.578 |
| newstest2018-ende-deueng.deu.eng 	| 38.8 	| 0.630 |
| newstest2019-deen-deueng.deu.eng 	| 34.9 	| 0.601 |
| Tatoeba-test.afr-eng.afr.eng 	| 61.3 	| 0.748 |
| Tatoeba-test.ang-eng.ang.eng 	| 6.4 	| 0.203 |
| Tatoeba-test.deu-eng.deu.eng 	| 47.5 	| 0.649 |
| Tatoeba-test.enm-eng.enm.eng 	| 15.9 	| 0.426 |
| Tatoeba-test.frr-eng.frr.eng 	| 6.1 	| 0.073 |
| Tatoeba-test.fry-eng.fry.eng 	| 25.5 	| 0.468 |
| Tatoeba-test.gos-eng.gos.eng 	| 12.5 	| 0.308 |
| Tatoeba-test.gsw-eng.gsw.eng 	| 8.5 	| 0.279 |
| Tatoeba-test.ksh-eng.ksh.eng 	| 8.4 	| 0.261 |
| Tatoeba-test.ltz-eng.ltz.eng 	| 27.3 	| 0.437 |
| Tatoeba-test.multi.eng 	| 47.5 	| 0.637 |
| Tatoeba-test.nds-eng.nds.eng 	| 30.1 	| 0.494 |
| Tatoeba-test.nld-eng.nld.eng 	| 57.5 	| 0.723 |
| Tatoeba-test.pdc-eng.pdc.eng 	| 28.9 	| 0.427 |
| Tatoeba-test.sco-eng.sco.eng 	| 45.3 	| 0.602 |
| Tatoeba-test.stq-eng.stq.eng 	| 20.1 	| 0.385 |
| Tatoeba-test.swg-eng.swg.eng 	| 13.8 	| 0.284 |
| Tatoeba-test.yid-eng.yid.eng 	| 14.2 	| 0.341 |

# opus-2020-07-19.zip

* dataset: opus
* model: transformer
* source language(s): afr ang_Latn deu enm_Latn frr fry gos gsw ksh ltz nds nld pdc sco stq swg yid
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-19.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-19.zip)
* test set translations: [opus-2020-07-19.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-19.test.txt)
* test set scores: [opus-2020-07-19.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-19.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newssyscomb2009-deueng.deu.eng 	| 26.7 	| 0.536 |
| news-test2008-deueng.deu.eng 	| 25.2 	| 0.529 |
| newstest2009-deueng.deu.eng 	| 24.5 	| 0.525 |
| newstest2010-deueng.deu.eng 	| 27.2 	| 0.559 |
| newstest2011-deueng.deu.eng 	| 24.9 	| 0.534 |
| newstest2012-deueng.deu.eng 	| 25.9 	| 0.543 |
| newstest2013-deueng.deu.eng 	| 28.8 	| 0.558 |
| newstest2014-deen-deueng.deu.eng 	| 29.5 	| 0.565 |
| newstest2015-ende-deueng.deu.eng 	| 30.6 	| 0.570 |
| newstest2016-ende-deueng.deu.eng 	| 36.1 	| 0.617 |
| newstest2017-ende-deueng.deu.eng 	| 31.7 	| 0.578 |
| newstest2018-ende-deueng.deu.eng 	| 38.8 	| 0.630 |
| newstest2019-deen-deueng.deu.eng 	| 34.9 	| 0.601 |
| Tatoeba-test.afr-eng.afr.eng 	| 61.3 	| 0.748 |
| Tatoeba-test.ang-eng.ang.eng 	| 6.4 	| 0.203 |
| Tatoeba-test.deu-eng.deu.eng 	| 47.5 	| 0.649 |
| Tatoeba-test.enm-eng.enm.eng 	| 15.9 	| 0.426 |
| Tatoeba-test.frr-eng.frr.eng 	| 6.1 	| 0.073 |
| Tatoeba-test.fry-eng.fry.eng 	| 25.5 	| 0.468 |
| Tatoeba-test.gos-eng.gos.eng 	| 12.5 	| 0.308 |
| Tatoeba-test.gsw-eng.gsw.eng 	| 8.5 	| 0.279 |
| Tatoeba-test.ksh-eng.ksh.eng 	| 8.4 	| 0.261 |
| Tatoeba-test.ltz-eng.ltz.eng 	| 27.3 	| 0.437 |
| Tatoeba-test.multi.eng 	| 47.5 	| 0.637 |
| Tatoeba-test.nds-eng.nds.eng 	| 30.1 	| 0.494 |
| Tatoeba-test.nld-eng.nld.eng 	| 57.5 	| 0.723 |
| Tatoeba-test.pdc-eng.pdc.eng 	| 28.9 	| 0.427 |
| Tatoeba-test.sco-eng.sco.eng 	| 45.3 	| 0.602 |
| Tatoeba-test.stq-eng.stq.eng 	| 20.1 	| 0.385 |
| Tatoeba-test.swg-eng.swg.eng 	| 13.8 	| 0.284 |
| Tatoeba-test.yid-eng.yid.eng 	| 14.2 	| 0.341 |

# opus-2020-07-26.zip

* dataset: opus
* model: transformer
* source language(s): afr ang_Latn deu enm_Latn frr fry gos gsw ksh ltz nds nld pdc sco stq swg yid
* target language(s): eng
* model: transformer
* pre-processing: normalization + SentencePiece (spm32k,spm32k)
* download: [opus-2020-07-26.zip](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-26.zip)
* test set translations: [opus-2020-07-26.test.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-26.test.txt)
* test set scores: [opus-2020-07-26.eval.txt](https://object.pouta.csc.fi/Tatoeba-MT-models/gmw-eng/opus-2020-07-26.eval.txt)

## Benchmarks

| testset               | BLEU  | chr-F |
|-----------------------|-------|-------|
| newssyscomb2009-deueng.deu.eng 	| 26.7 	| 0.536 |
| news-test2008-deueng.deu.eng 	| 25.2 	| 0.529 |
| newstest2009-deueng.deu.eng 	| 24.5 	| 0.525 |
| newstest2010-deueng.deu.eng 	| 27.2 	| 0.559 |
| newstest2011-deueng.deu.eng 	| 24.9 	| 0.534 |
| newstest2012-deueng.deu.eng 	| 25.9 	| 0.543 |
| newstest2013-deueng.deu.eng 	| 28.8 	| 0.558 |
| newstest2014-deen-deueng.deu.eng 	| 29.5 	| 0.565 |
| newstest2015-ende-deueng.deu.eng 	| 30.6 	| 0.570 |
| newstest2016-ende-deueng.deu.eng 	| 36.1 	| 0.617 |
| newstest2017-ende-deueng.deu.eng 	| 31.7 	| 0.578 |
| newstest2018-ende-deueng.deu.eng 	| 38.8 	| 0.630 |
| newstest2019-deen-deueng.deu.eng 	| 34.9 	| 0.601 |
| Tatoeba-test.afr-eng.afr.eng 	| 61.3 	| 0.748 |
| Tatoeba-test.ang-eng.ang.eng 	| 6.4 	| 0.203 |
| Tatoeba-test.deu-eng.deu.eng 	| 47.5 	| 0.649 |
| Tatoeba-test.enm-eng.enm.eng 	| 15.9 	| 0.426 |
| Tatoeba-test.frr-eng.frr.eng 	| 6.1 	| 0.073 |
| Tatoeba-test.fry-eng.fry.eng 	| 25.5 	| 0.468 |
| Tatoeba-test.gos-eng.gos.eng 	| 12.5 	| 0.308 |
| Tatoeba-test.gsw-eng.gsw.eng 	| 8.5 	| 0.279 |
| Tatoeba-test.ksh-eng.ksh.eng 	| 8.4 	| 0.261 |
| Tatoeba-test.ltz-eng.ltz.eng 	| 27.3 	| 0.437 |
| Tatoeba-test.multi.eng 	| 47.5 	| 0.637 |
| Tatoeba-test.nds-eng.nds.eng 	| 30.1 	| 0.494 |
| Tatoeba-test.nld-eng.nld.eng 	| 57.5 	| 0.723 |
| Tatoeba-test.pdc-eng.pdc.eng 	| 28.9 	| 0.427 |
| Tatoeba-test.sco-eng.sco.eng 	| 45.3 	| 0.602 |
| Tatoeba-test.stq-eng.stq.eng 	| 20.1 	| 0.385 |
| Tatoeba-test.swg-eng.swg.eng 	| 13.8 	| 0.284 |
| Tatoeba-test.yid-eng.yid.eng 	| 14.2 	| 0.341 |

